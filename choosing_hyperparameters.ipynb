{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROSS VALIDATION FOR DIFFERENT MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from crossvalidation import *\n",
    "from preprocessing import *\n",
    "from dataset_splitting import *\n",
    "from feature_engineering import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading train data\n",
    "\n",
    "filename = 'train.csv'\n",
    "data_folder = './data/'\n",
    "file_path = data_folder + filename\n",
    "y,tx,ids,features = load_train_data(file_path)\n",
    "\n",
    "# Computing preprocessing routine\n",
    "\n",
    "list_subsets, list_features, y_0, y_1, y_2_3, columns_to_drop_in_subsets = preprocessing(tx,y,ids,features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to introduce interaction factors between variables during the preprocessing routine. \n",
    "However, there is not statistical significance that multiplying variables with trigonometric functions \n",
    "may improve the model performance. Therefore, since trigonometric values are the last columns of each \n",
    "dataset, we save in a list how many columns are related to trigonometric values in each subset in order \n",
    "not to multiply columns with them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many_trig_features=[2,1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining parameters to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-7,-3,5)\n",
    "degrees = [3,5,7]\n",
    "k_fold = 4\n",
    "gamma = 0.1\n",
    "max_iters = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining lists to save optimal degrees and lambdas for each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lambdas = [0]*3\n",
    "optimal_degrees = [1]*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing cross validation on subsets_0 for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice of lambda which leads to the best test rmse is 0.00000 with a test rmse of 0.335. The best degree is 7.0\n"
     ]
    }
   ],
   "source": [
    "optimal_degrees[0], optimal_lambdas[0], best_rmse = cross_validation_demo_ridge(y_0, list_subsets[0], k_fold, lambdas, degrees,\n",
    "                                                                               how_many_trig_features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Doing cross validation on subsets_1 for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice of lambda which leads to the best test rmse is 0.00000 with a test rmse of 0.372. The best degree is 7.0\n"
     ]
    }
   ],
   "source": [
    "optimal_degrees[1], optimal_lambdas[1], best_rmse = cross_validation_demo_ridge(y_1, list_subsets[1], k_fold, lambdas, degrees,\n",
    "                                                                               how_many_trig_features[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Doing cross validation on subsets_2_3 for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice of lambda which leads to the best test rmse is 0.00000 with a test rmse of 0.348. The best degree is 7.0\n"
     ]
    }
   ],
   "source": [
    "optimal_degrees[2], optimal_lambdas[2], best_rmse = cross_validation_demo_ridge(y_2_3, list_subsets[2], k_fold, lambdas, degrees,\n",
    "                                                                               how_many_trig_features[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGULARIZED LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing cross validation on subsets_0 for regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k_fold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_degree,best_lambda,_ \u001b[38;5;241m=\u001b[39m cross_validation_demo_log(y_0, list_subsets[\u001b[38;5;241m0\u001b[39m], \u001b[43mk_fold\u001b[49m, lambdas, gamma, max_iters,degrees, how_many_trig_features[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'k_fold' is not defined"
     ]
    }
   ],
   "source": [
    "best_degree,best_lambda,_ = cross_validation_demo_log(y_0, list_subsets[0], k_fold, lambdas, gamma, max_iters,degrees, how_many_trig_features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Doing cross validation on subsets_1 for regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice of lambda which leads to the best test logloss is 0.00000 with a test logloss of 0.419. The best degree is 3.0\n"
     ]
    }
   ],
   "source": [
    "best_degree,best_lambda,_ = cross_validation_demo_log(y_1, list_subsets[1], k_fold, lambdas, gamma, max_iters,degrees, how_many_trig_features[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Doing cross validation on subsets_2_3 for regularized logistc regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice of lambda which leads to the best test logloss is 0.00000 with a test logloss of 0.377. The best degree is 3.0\n"
     ]
    }
   ],
   "source": [
    "best_degree,best_lambda,_ = cross_validation_demo_log(y_2_3, list_subsets[2], k_fold, lambdas, gamma, max_iters,degrees, how_many_trig_features[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### COMPUTING ACCURACY FOR RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Computing accuracy for ridge regression using optimal values as hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_outputs = [y_0,y_1,y_2_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train accuracy: 0.8345508006077496\n",
      "std train accuracy: 0.00042991452791422486\n",
      "Average test accuracy: 0.8338036974321823\n",
      "std train accuracy: 0.000783408952673735\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(list_outputs,list_subsets,0.7,[0.00001,0.00001,0.00001],[7,7,7],how_many_trig_features,pred_threshold = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPUTING ACCURACY FOR REGULARIZED LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing accuracy for regularized logistic regression using optimal values as hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train accuracy: 0.8320193575709321\n",
      "std train accuracy: 0.00046693834276353334\n",
      "Average test accuracy: 0.8319370556540728\n",
      "std train accuracy: 0.0010278248657757754\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(list_outputs,list_subsets,0.7,[0.0000, 0.0000, 0.0000],[3,3,3],how_many_trig_features, pred_threshold=0.55,method = 'logistic',gamma = 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e9c25df0253b19710fd2eabc0119b804c820fc74e8ba938ebab686d76fc4dfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
