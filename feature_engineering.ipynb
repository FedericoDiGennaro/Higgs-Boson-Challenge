{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from crossvalidation import *\n",
    "from preprocessing import *\n",
    "from dataset_splitting import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'train.csv'\n",
    "data_folder = './data/'\n",
    "file_path = data_folder + filename\n",
    "y,tx,ids,features = load_train_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving logical masks to divide the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column = np.where(features == 'PRI_jet_num')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_0,mask_1,mask_2_3 = divide_indices_in_subsets(tx,categorical_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing categorical column since it is now useless "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = np.delete(tx,categorical_column,axis = 1)\n",
    "# since we delete the column in tx, we also delete the name of the categorical feature used to divide the dataset\n",
    "features = np.delete(features,categorical_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset, the output vector and ids w.r.t according to the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_0, y_0, ids_0 = divide_dataset_in_subsets(tx,y,ids,mask_0)\n",
    "subset_1, y_1, ids_1 = divide_dataset_in_subsets(tx,y,ids,mask_1)\n",
    "subset_2_3, y_2_3, ids_2_3 = divide_dataset_in_subsets(tx,y,ids,mask_2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a list containing each subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_subsets = [subset_0,subset_1,subset_2_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list containing features for each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_features = [features]*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing missing values in each subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(3):\n",
    "    list_subsets[idx],list_features[idx] = managing_missing_values(list_subsets[idx],features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last column in subset_0 is a zeros vector (see the documentation). Therefore, we drop it not to have problems when\n",
    "standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_subsets[0] = np.delete(list_subsets[0],-1, 1)\n",
    "list_features[0] = np.delete(list_features[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capping outliers in each subset by replacing them with 5% or 95% percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(3):\n",
    "    list_subsets[idx] = capping_outliers(list_subsets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining trigonometric features (sine and cosine) starting from columns related to angle values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_angles_0 = [11, 14, 16]\n",
    "columns_angles_1 = [11, 14, 16, 20]\n",
    "columns_angles_2 = [15, 18, 20, 27]\n",
    "\n",
    "list_subsets[0],list_features[0] = trigonometrics(list_subsets[0],columns_angles_0,list_features[0])\n",
    "list_subsets[1],list_features[1] = trigonometrics(list_subsets[1],columns_angles_1,list_features[1])\n",
    "list_subsets[2],list_features[2] = trigonometrics(list_subsets[2],columns_angles_2,list_features[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying logarithmic transformation to skewed distributions in each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non runnare fino a quando fede non rivede quali sono quelle giuste\n",
    "\n",
    "#to_log_c0 = [1, 2, 3, 4,6,7,8,10,12,15] \n",
    "#to_log_c1 = [1,2,3,4,6,7,8,10,12,15,16,18]\n",
    "#to_log_c2 = [1,2,3,4,6,9,10,11,14,16,19,20,23,25]\n",
    "\n",
    "#list_subsets[0][:,to_log_c0] =log_transform(list_subsets[0][:,to_log_c0])\n",
    "#list_subsets[1][:,to_log_c1] = log_transform(list_subsets[1][:,to_log_c1])\n",
    "#list_subsets[2][:,to_log_c2] = log_transform(list_subsets[2][:,to_log_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PER FEDE: ripetere il plot delle feature e rivedere quali sono inutili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing interaction factors in each subsets by multypling pairs of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we build interaction factors between columns. Each subset still doesn't have an offset column, which will be added later\n",
    "# The cell takes time, the number of columns grows a lot. We must remove some columns before doing this expansion\n",
    "#for idx in range(3):\n",
    "    #list_subsets[idx] = build_interaction_factors(list_subsets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing data before using them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_std = []\n",
    "for idx in range(3):\n",
    "    list_subsets[idx],mean,std = standardize(list_subsets[idx])\n",
    "    list_means.append(mean)\n",
    "    list_std.append(std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e9c25df0253b19710fd2eabc0119b804c820fc74e8ba938ebab686d76fc4dfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
